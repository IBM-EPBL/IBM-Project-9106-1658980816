{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acf764df",
   "metadata": {},
   "source": [
    "# Sprint 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29c70ca",
   "metadata": {},
   "source": [
    "# Import the Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e40d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils #used for one-hot encoding\n",
    "from tensorflow.keras.datasets import mnist #mnist dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc02f4c2",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c44c791",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#splitting the mnist data into train and test data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51b1dac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#shape is used to give the dimension values\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fb2230",
   "metadata": {},
   "source": [
    "# Analyzing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05bb4de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the first image\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37eaa219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing label of first image\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "715b381c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19dff155b10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#used for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "#plotting the index=0 image\n",
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fa1119",
   "metadata": {},
   "source": [
    "# Reshaping Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0c197da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping to format which CNN expects(batch, height, width, channels)\n",
    "X_train = X_train.reshape(60000, 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(10000, 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a32aefe",
   "metadata": {},
   "source": [
    "# Applying One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c05a993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the number of classes in a variable\n",
    "number_of_classes = 10\n",
    "#converts the output into binary format(0's and 1's)\n",
    "Y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, number_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6172455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the label after conversion\n",
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05583cf",
   "metadata": {},
   "source": [
    "# Sprint 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab4f4af",
   "metadata": {},
   "source": [
    "# Add CNN Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af4b3918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it is a plain stack of layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "#A layer consists of a tensor-in tensor-out computation function\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#Dense-Dense Layer is the regular deeply connected neural network\n",
    "#Flatten-used for flattening the input or change the dimension\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "#Convolutional Layer\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "#optimizer\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c3d69b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating the model\n",
    "model = Sequential()\n",
    "\n",
    "#adding the model layers\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(28, 28, 1), activation=\"relu\"))\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "\n",
    "#flatten the dimesions of the image\n",
    "model.add(Flatten())\n",
    "\n",
    "#output layer with 10 neurons\n",
    "model.add(Dense(number_of_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db6a41f",
   "metadata": {},
   "source": [
    "# Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cbe8cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb80e6b9",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12376ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 156s 83ms/step - loss: 0.2315 - accuracy: 0.9485 - val_loss: 0.1089 - val_accuracy: 0.9655\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 158s 84ms/step - loss: 0.0684 - accuracy: 0.9796 - val_loss: 0.1011 - val_accuracy: 0.9709\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 165s 88ms/step - loss: 0.0492 - accuracy: 0.9845 - val_loss: 0.0900 - val_accuracy: 0.9738\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 162s 86ms/step - loss: 0.0336 - accuracy: 0.9893 - val_loss: 0.0970 - val_accuracy: 0.9777\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 153s 82ms/step - loss: 0.0274 - accuracy: 0.9908 - val_loss: 0.1009 - val_accuracy: 0.9765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19dfe12dff0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model\n",
    "model.fit(X_train, Y_train, batch_size=32, epochs=5, validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026d59c4",
   "metadata": {},
   "source": [
    "# Observing the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4d9467c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics (Test Loss & Test Accuracy): \n",
      "[0.1009373664855957, 0.9764999747276306]\n"
     ]
    }
   ],
   "source": [
    "#evaluation of the model\n",
    "metrics = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Metrics (Test Loss & Test Accuracy): \")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddae48d0",
   "metadata": {},
   "source": [
    "# Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2494a07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 171ms/step\n",
      "[[3.87378965e-14 1.22201112e-20 2.70703626e-13 1.01162767e-11\n",
      "  2.68388663e-16 4.12979437e-16 8.89591264e-24 1.00000000e+00\n",
      "  5.69351892e-11 3.61267418e-12]\n",
      " [3.04165276e-13 2.24705603e-13 1.00000000e+00 6.86506143e-15\n",
      "  2.97049034e-13 1.62425163e-21 1.51806814e-11 1.54766518e-17\n",
      "  8.39281918e-15 7.23848821e-22]\n",
      " [1.01410803e-10 9.99964952e-01 7.97218547e-07 4.06620987e-11\n",
      "  3.41548584e-05 1.55060619e-07 4.07343104e-10 2.16682805e-09\n",
      "  1.29432687e-08 3.78075100e-08]\n",
      " [1.00000000e+00 5.05753447e-17 8.09822858e-13 1.69388908e-15\n",
      "  2.66154947e-15 7.91606228e-14 2.50689313e-12 1.39006433e-14\n",
      "  1.56500409e-13 1.59382096e-09]\n",
      " [1.63105071e-13 4.77125824e-16 1.14359668e-11 8.83585807e-14\n",
      "  1.00000000e+00 3.45050513e-13 2.61946262e-18 2.15790927e-12\n",
      "  2.41069317e-13 9.99037866e-11]\n",
      " [5.47705145e-11 9.99919415e-01 1.26692230e-08 5.01515366e-12\n",
      "  5.79868174e-06 2.05035099e-12 4.36350961e-13 7.18247611e-05\n",
      "  2.28491757e-07 2.59825993e-06]\n",
      " [2.37583769e-20 1.20451027e-08 3.77478691e-12 1.65486479e-15\n",
      "  1.00000000e+00 1.60514846e-09 1.07594484e-17 3.74096221e-09\n",
      "  5.01521384e-08 3.16742521e-09]\n",
      " [2.94677911e-13 9.33811847e-11 2.17130811e-08 2.64582162e-10\n",
      "  9.44645961e-08 1.00025155e-09 5.74344785e-17 3.41029809e-11\n",
      "  1.29531770e-06 9.99998569e-01]\n",
      " [9.83049091e-08 7.54506795e-15 3.51617369e-14 1.80999031e-12\n",
      "  8.55691462e-10 9.85015869e-01 1.49575174e-02 2.92950191e-18\n",
      "  2.64830633e-05 2.92172531e-09]\n",
      " [1.35454690e-12 7.18363814e-19 6.60014213e-15 3.32864205e-12\n",
      "  2.13855083e-06 2.92830105e-13 1.56811911e-16 4.44172591e-04\n",
      "  1.23335508e-06 9.99552429e-01]]\n"
     ]
    }
   ],
   "source": [
    "#slicing the first 4 images from x_test data and printing the predicted output\n",
    "prediction = model.predict(X_test[:10])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fe6fe74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#printing our labels from first 4 images\n",
    "print(np.argmax(prediction, axis=1))\n",
    "\n",
    "#printing the actual labels\n",
    "print(Y_test[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd3cbf3",
   "metadata": {},
   "source": [
    "# Sprint 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e311e331",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2fabd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029ddaa0",
   "metadata": {},
   "source": [
    "# Test with Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0276846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 198ms/step\n",
      "[[0.09645228 0.10865606 0.08577293 0.13518178 0.07421888 0.18881202\n",
      "  0.08243676 0.04284775 0.07271596 0.1129057 ]]\n",
      "[5]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "[[0.09645228 0.10865606 0.08577293 0.13518178 0.07421888 0.18881202\n",
      "  0.08243676 0.04284775 0.07271596 0.1129057 ]]\n",
      "[5]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[0.09645228 0.10865606 0.08577293 0.13518178 0.07421888 0.18881202\n",
      "  0.08243676 0.04284775 0.07271596 0.1129057 ]]\n",
      "[5]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "[[0.09645228 0.10865606 0.08577293 0.13518178 0.07421888 0.18881202\n",
      "  0.08243676 0.04284775 0.07271596 0.1129057 ]]\n",
      "[5]\n"
     ]
    }
   ],
   "source": [
    "#importing the keras libraries and packages\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#loading the model\n",
    "model=load_model(r'model.h5')\n",
    "\n",
    "#used for manipulating image uploaded by the user\n",
    "from PIL import Image\n",
    "\n",
    "#used for numerical analysis\n",
    "import numpy as np\n",
    "\n",
    "for index in range(4):\n",
    "    #convert image to required format\n",
    "    img=Image.open('test0.png').convert(\"L\")\n",
    "    \n",
    "    #resizing of input image\n",
    "    img = img.resize((28, 28))\n",
    "    \n",
    "    #converting to image\n",
    "    img2arr = np.array(img)\n",
    "    \n",
    "    #reshaping according to our requirement\n",
    "    img2arr = img2arr.reshape(1, 28, 28, 1)\n",
    "\n",
    "    #Predicting the Test set results\n",
    "    y_pred=model.predict(img2arr)\n",
    "    print(y_pred)\n",
    "    print(np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5a3f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc3c13037f53e823b9b01006dac3a0963de174145f1a26c6973eb8358cd9fc43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
